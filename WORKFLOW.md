# AI News Assistant - System Workflow

## ğŸ”„ Complete System Workflow

### **Phase 1: Data Collection & Ingestion**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Reddit API    â”‚    â”‚  Google News    â”‚    â”‚   Pushshift     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   (Fallback)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reddit Scraper  â”‚    â”‚ News Scraper     â”‚    â”‚ Fallback Scraperâ”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Subreddit     â”‚    â”‚ â€¢ Topic Search   â”‚    â”‚ â€¢ Historical    â”‚
â”‚   Monitoring    â”‚    â”‚ â€¢ RSS Feeds      â”‚    â”‚   Data          â”‚
â”‚ â€¢ Query Search  â”‚    â”‚ â€¢ API Calls      â”‚    â”‚ â€¢ Archive       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Data Ingestion       â”‚
                    â”‚                         â”‚
                    â”‚ â€¢ Duplicate Detection   â”‚
                    â”‚ â€¢ Content Validation    â”‚
                    â”‚ â€¢ Metadata Extraction    â”‚
                    â”‚ â€¢ Rate Limiting         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     SQLite Database     â”‚
                    â”‚                         â”‚
                    â”‚ â€¢ Posts Table           â”‚
                    â”‚ â€¢ Topics Table          â”‚
                    â”‚ â€¢ Trend Scores          â”‚
                    â”‚ â€¢ Chat History          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Phase 2: AI Processing Pipeline**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Raw Posts Data      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Preprocessing         â”‚
â”‚                         â”‚
â”‚ â€¢ Text Cleaning         â”‚
â”‚ â€¢ URL Extraction        â”‚
â”‚ â€¢ Emoji Handling        â”‚
â”‚ â€¢ Language Detection    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentiment Analysis     â”‚
â”‚                         â”‚
â”‚ â€¢ RoBERTa Model         â”‚
â”‚ â€¢ Score Calculation      â”‚
â”‚ â€¢ Label Assignment       â”‚
â”‚ â€¢ Confidence Scoring    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Topic Modeling        â”‚
â”‚                         â”‚
â”‚ â€¢ BERTopic Clustering   â”‚
â”‚ â€¢ Keyword Extraction    â”‚
â”‚ â€¢ Topic Assignment      â”‚
â”‚ â€¢ Drift Detection       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Embeddings      â”‚
â”‚                         â”‚
â”‚ â€¢ Sentence Transformers â”‚
â”‚ â€¢ FAISS Index Building  â”‚
â”‚ â€¢ Similarity Search     â”‚
â”‚ â€¢ Semantic Clustering   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Trend Analysis        â”‚
â”‚                         â”‚
â”‚ â€¢ Engagement Scoring    â”‚
â”‚ â€¢ Velocity Calculation   â”‚
â”‚ â€¢ Momentum Detection     â”‚
â”‚ â€¢ Alert Generation      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Phase 3: User Interaction & Response**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Frontend Request      â”‚
â”‚                         â”‚
â”‚ â€¢ Dashboard Load        â”‚
â”‚ â€¢ Chat Message          â”‚
â”‚ â€¢ Sentiment Query       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FastAPI Backend      â”‚
â”‚                         â”‚
â”‚ â€¢ Request Validation    â”‚
â”‚ â€¢ Authentication        â”‚
â”‚ â€¢ Rate Limiting         â”‚
â”‚ â€¢ CORS Handling         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Business Logic        â”‚
â”‚                         â”‚
â”‚ â€¢ Data Aggregation      â”‚
â”‚ â€¢ AI Model Inference    â”‚
â”‚ â€¢ Response Generation   â”‚
â”‚ â€¢ Caching Strategy      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Database Queries      â”‚
â”‚                         â”‚
â”‚ â€¢ SQLAlchemy ORM        â”‚
â”‚ â€¢ Async Operations      â”‚
â”‚ â€¢ Connection Pooling    â”‚
â”‚ â€¢ Transaction Managementâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Model Pipeline     â”‚
â”‚                         â”‚
â”‚ â€¢ Gemini Integration    â”‚
â”‚ â€¢ Sentiment Analysis    â”‚
â”‚ â€¢ Topic Classification   â”‚
â”‚ â€¢ Summary Generation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response Formatting   â”‚
â”‚                         â”‚
â”‚ â€¢ JSON Serialization    â”‚
â”‚ â€¢ Error Handling        â”‚
â”‚ â€¢ Logging & Monitoring  â”‚
â”‚ â€¢ Performance Metrics   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend Response     â”‚
â”‚                         â”‚
â”‚ â€¢ React State Update    â”‚
â”‚ â€¢ UI Component Render   â”‚
â”‚ â€¢ User Interaction      â”‚
â”‚ â€¢ Real-time Updates     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Component Interactions

### **Backend API Endpoints**

| Endpoint | Method | Purpose | Input | Output |
|----------|--------|---------|-------|--------|
| `/api/stats` | GET | Dashboard statistics | None | Stats object |
| `/api/sentiment-distribution/{source}` | GET | Sentiment breakdown | Source name | Distribution data |
| `/api/recent-posts/{source}` | GET | Recent posts | Source, limit | Post array |
| `/api/chat` | POST | Chat interaction | Query, session_id | AI response |
| `/api/analyze-sentiment` | POST | Topic analysis | Topic string | Analysis results |
| `/api/compare-sentiment` | POST | Cross-source comparison | Topic string | Comparison data |
| `/api/refresh` | POST | Data refresh | None | Refresh status |

### **Database Schema**

```sql
-- Posts table
CREATE TABLE posts (
    id INTEGER PRIMARY KEY,
    post_id TEXT UNIQUE,
    title TEXT,
    content TEXT,
    url TEXT,
    subreddit TEXT,
    source TEXT,
    score INTEGER,
    num_comments INTEGER,
    sentiment_label TEXT,
    sentiment_score REAL,
    topic_id INTEGER,
    is_trending BOOLEAN,
    created_at TIMESTAMP,
    FOREIGN KEY (topic_id) REFERENCES topics(id)
);

-- Topics table
CREATE TABLE topics (
    id INTEGER PRIMARY KEY,
    name TEXT,
    keywords TEXT,
    num_posts INTEGER,
    avg_sentiment REAL,
    created_at TIMESTAMP
);

-- Trend scores table
CREATE TABLE trend_scores (
    id INTEGER PRIMARY KEY,
    post_id INTEGER,
    engagement_score REAL,
    velocity_score REAL,
    momentum_score REAL,
    total_score REAL,
    FOREIGN KEY (post_id) REFERENCES posts(id)
);
```

### **AI Model Pipeline**

1. **Text Preprocessing**
   - Remove special characters
   - Handle URLs and mentions
   - Normalize text format
   - Language detection

2. **Sentiment Analysis**
   - Load RoBERTa model
   - Tokenize input text
   - Generate sentiment scores
   - Assign labels (positive/negative/neutral)

3. **Topic Modeling**
   - Extract embeddings
   - Apply BERTopic clustering
   - Generate topic keywords
   - Assign topic IDs

4. **Vector Search**
   - Create FAISS index
   - Store embeddings
   - Enable similarity search
   - Support semantic queries

## ğŸš€ Deployment Workflow

### **Development Environment**
```bash
# 1. Environment setup
cp env.example .env
# Edit .env with your API keys

# 2. Backend setup
pip install -r requirements.txt
python -c "from backend.db import init_db; import asyncio; asyncio.run(init_db())"

# 3. Frontend setup
cd frontend
npm install

# 4. Launch system
python launcher.py
```

### **Production Deployment**
```bash
# 1. Environment configuration
export REDDIT_CLIENT_ID="your_id"
export REDDIT_CLIENT_SECRET="your_secret"
export GEMINI_API_KEY="your_key"

# 2. Database setup
python -c "from backend.db import init_db; import asyncio; asyncio.run(init_db())"

# 3. Backend deployment
gunicorn backend.api:app -w 4 -k uvicorn.workers.UvicornWorker

# 4. Frontend build
cd frontend
npm run build
# Serve with nginx or similar
```

## ğŸ“Š Monitoring & Analytics

### **Performance Metrics**
- API response times
- Database query performance
- AI model inference speed
- Memory usage patterns
- Error rates and types

### **Business Metrics**
- User engagement rates
- Chat session duration
- Sentiment accuracy scores
- Topic trend detection
- Data freshness metrics

### **System Health Checks**
- Database connectivity
- API endpoint availability
- AI model loading status
- External service dependencies
- Resource utilization

## ğŸ”’ Security Considerations

### **API Security**
- Rate limiting per IP
- Request validation
- CORS configuration
- Input sanitization
- SQL injection prevention

### **Data Privacy**
- No personal data storage
- Anonymized user sessions
- Secure API key management
- Environment variable protection
- Audit logging

### **Model Security**
- Model versioning
- Input validation
- Output sanitization
- Error handling
- Resource limits

## ğŸ› Error Handling & Recovery

### **Common Error Scenarios**
1. **API Rate Limiting**: Implement exponential backoff
2. **Database Connection Loss**: Connection pooling and retry logic
3. **Model Loading Failures**: Fallback to simpler models
4. **Memory Exhaustion**: Garbage collection and resource monitoring
5. **Network Timeouts**: Circuit breaker pattern

### **Recovery Strategies**
- Automatic retry mechanisms
- Graceful degradation
- Fallback data sources
- Health check endpoints
- Alert notifications

## ğŸ“ˆ Scalability Considerations

### **Horizontal Scaling**
- Stateless API design
- Database connection pooling
- Load balancer configuration
- Container orchestration
- Microservice architecture

### **Vertical Scaling**
- Memory optimization
- CPU utilization monitoring
- Database indexing
- Caching strategies
- Resource allocation

---

This workflow ensures a robust, scalable, and maintainable AI news analysis system that can handle real-time data processing and user interactions efficiently.
