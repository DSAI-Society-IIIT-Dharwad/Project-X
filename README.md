# InQuiro - Project X

A comprehensive AI-powered news analysis platform that combines Reddit discussions with Google News coverage, providing real-time sentiment analysis, trend detection, and intelligent chat capabilities.

## ğŸš€ Features

### ğŸ“Š **Unified Dashboard**
- Real-time statistics from Reddit and Google News
- Sentiment comparison between sources
- Trending topics and engagement metrics
- Interactive charts and visualizations

### ğŸ’¬ **AI Chat Assistant**
- Intelligent Q&A based on recent Reddit discussions
- Real-time search and analysis
- Confidence scoring and source attribution
- Session-based conversation history

### ğŸ“ˆ **Sentiment Analysis**
- Topic-based sentiment analysis across Reddit
- Subreddit-specific sentiment breakdowns
- Temporal sentiment trends
- Keyword extraction and analysis

### ğŸ”„ **Real-time Data Processing**
- Automated Reddit scraping
- Google News integration
- Sentiment scoring with AI models
- Topic modeling and clustering

## ğŸ—ï¸ Architecture

### **Frontend (React + Vite)**
- Modern React 18 with hooks
- Tailwind CSS for styling
- Framer Motion for animations
- Recharts for data visualization
- Zustand for state management

### **Backend (FastAPI + Python)**
- Async FastAPI for high performance
- SQLAlchemy with async SQLite
- PRAW for Reddit API integration
- Google Gemini for AI analysis
- FAISS for vector similarity search

### **AI Pipeline**
- RoBERTa for sentiment analysis
- Sentence Transformers for embeddings
- BERTopic for topic modeling
- Custom ML pipelines for trend detection

## ğŸ“ Project Structure

```
Project-X/
â”œâ”€â”€ ğŸ“ app/                          # Application modules
â”‚   â”œâ”€â”€ ai_assistant.py              # AI assistant logic
â”‚   â”œâ”€â”€ dashboard.py                 # Dashboard analytics
â”‚   â””â”€â”€ professional_dashboard.py     # Professional dashboard
â”œâ”€â”€ ğŸ“ backend/                      # Backend API
â”‚   â”œâ”€â”€ api.py                       # Main API (full features)
â”‚   â”œâ”€â”€ api_simple.py                # Simplified API
â”‚   â”œâ”€â”€ api_mock.py                  # Mock API for testing
â”‚   â”œâ”€â”€ db.py                        # Database configuration
â”‚   â”œâ”€â”€ models.py                    # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas.py                   # Pydantic schemas
â”‚   â”œâ”€â”€ ingest.py                    # Data ingestion
â”‚   â””â”€â”€ chat_storage.py              # Chat history storage
â”œâ”€â”€ ğŸ“ frontend/                     # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/              # Reusable components
â”‚   â”‚   â”‚   â”œâ”€â”€ Layout.jsx           # Main layout
â”‚   â”‚   â”‚   â”œâ”€â”€ LoadingSpinner.jsx   # Loading states
â”‚   â”‚   â”‚   â”œâ”€â”€ MetricCard.jsx       # Dashboard metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ PostCard.jsx         # Post display
â”‚   â”‚   â”‚   â”œâ”€â”€ LoadingDots.jsx      # Chat loading
â”‚   â”‚   â”‚   â””â”€â”€ SentimentResults.jsx # Analysis results
â”‚   â”‚   â”œâ”€â”€ pages/                   # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx        # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatAssistant.jsx    # Chat interface
â”‚   â”‚   â”‚   â””â”€â”€ SentimentAnalysis.jsx # Sentiment page
â”‚   â”‚   â”œâ”€â”€ services/                # API services
â”‚   â”‚   â”‚   â””â”€â”€ api.js               # API client
â”‚   â”‚   â””â”€â”€ store/                   # State management
â”‚   â”‚       â””â”€â”€ useStore.js          # Zustand store
â”‚   â”œâ”€â”€ package.json                 # Frontend dependencies
â”‚   â””â”€â”€ tailwind.config.js          # Tailwind configuration
â”œâ”€â”€ ğŸ“ pipeline/                     # ML Pipeline
â”‚   â”œâ”€â”€ embeddings.py                # Vector embeddings
â”‚   â”œâ”€â”€ sentiment.py                 # Sentiment analysis
â”‚   â”œâ”€â”€ topic_model.py               # Topic modeling
â”‚   â”œâ”€â”€ trend_score.py               # Trend scoring
â”‚   â”œâ”€â”€ topic_drift.py               # Topic drift detection
â”‚   â”œâ”€â”€ summary.py                   # Text summarization
â”‚   â”œâ”€â”€ preprocess.py                # Data preprocessing
â”‚   â””â”€â”€ quick_pipeline.py            # Quick analysis pipeline
â”œâ”€â”€ ğŸ“ scraper/                      # Data Scrapers
â”‚   â”œâ”€â”€ reddit_scraper.py            # Reddit data collection
â”‚   â”œâ”€â”€ google_news_scraper.py       # Google News scraping
â”‚   â””â”€â”€ push_shift_fallback.py       # Pushshift fallback
â”œâ”€â”€ ğŸ“ models/                       # AI Models (created at runtime)
â”‚   â””â”€â”€ faiss_index/                 # FAISS vector index
â”œâ”€â”€ ğŸ“„ config.py                     # Configuration management
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ launcher.py                   # System launcher
â”œâ”€â”€ ğŸ“„ env.example                   # Environment template
â””â”€â”€ ğŸ“„ README.md                     # This file
```

## ğŸ”„ System Workflow

### **1. Data Collection**
```
Reddit API â†’ Reddit Scraper â†’ Database
Google News â†’ News Scraper â†’ Database
```

### **2. Data Processing**
```
Raw Posts â†’ Preprocessing â†’ Sentiment Analysis â†’ Topic Modeling â†’ Vector Embeddings
```

### **3. Analysis Pipeline**
```
Posts â†’ FAISS Index â†’ Similarity Search â†’ Trend Detection â†’ Dashboard Updates
```

### **4. User Interaction**
```
Frontend Request â†’ API Endpoint â†’ Database Query â†’ AI Analysis â†’ Response
```

## ğŸ› ï¸ Installation & Setup

### **Prerequisites**
- Python 3.8+
- Node.js 16+
- npm or yarn
- Reddit API credentials
- Google Gemini API key

### **1. Clone Repository**
```bash
git clone <repository-url>
cd Project-X
```

### **2. Environment Setup**
```bash
# Copy environment template
cp env.example .env

# Edit .env with your API keys
nano .env
```

### **3. Backend Setup**
```bash
# Install Python dependencies
pip install -r requirements.txt

# Initialize database
cd backend
python -c "
import asyncio
import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd().parent))
from backend.db import init_db
asyncio.run(init_db())
print('Database initialized!')
"
```

### **4. Frontend Setup**
```bash
# Install Node.js dependencies
cd frontend
npm install
```

### **5. Launch System**
```bash
# From project root
python launcher.py
```

## ğŸŒ Access Points

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Interactive API**: http://localhost:8000/redoc

## ğŸ”§ Configuration

### **Environment Variables**
Key configuration options in `.env`:

```bash
# Reddit API
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
REDDIT_USER_AGENT=your_user_agent

# Google Gemini
GEMINI_API_KEY=your_gemini_key

# Database
DATABASE_URL=sqlite+aiosqlite:///./news_bot.db

# Scraping
SCRAPE_LIMIT=100
SUBREDDITS=news,worldnews,politics,technology
```

### **Model Configuration**
- **Sentiment Model**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **Embedding Model**: `all-MiniLM-L6-v2`
- **Topic Model**: BERTopic with custom configuration

## ğŸ“Š API Endpoints

### **Dashboard**
- `GET /api/stats` - Overall statistics
- `GET /api/sentiment-distribution/{source}` - Sentiment breakdown
- `GET /api/recent-posts/{source}` - Recent posts

### **Chat**
- `POST /api/chat` - Send chat message
- `GET /api/chat-history/{session_id}` - Get chat history

### **Analysis**
- `POST /api/analyze-sentiment` - Topic sentiment analysis
- `POST /api/compare-sentiment` - Cross-source comparison
- `POST /api/refresh` - Refresh data

## ğŸš€ Development

### **Running in Development Mode**
```bash
# Backend with hot reload
cd backend
python -m uvicorn api_mock:app --reload --host 0.0.0.0 --port 8000

# Frontend with hot reload
cd frontend
npm run dev
```

### **Testing**
```bash
# Test API endpoints
curl http://localhost:8000/api/stats
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "session_id": "test123"}'
```

### **Database Management**
```bash
# Initialize database
python -c "from backend.db import init_db; import asyncio; asyncio.run(init_db())"

# Check database status
python -c "from backend.db import check_connection; import asyncio; asyncio.run(check_connection())"
```

## ğŸ”’ Security Considerations

- **API Keys**: Store securely in `.env` file
- **CORS**: Configure allowed origins for production
- **Rate Limiting**: Implement request throttling
- **Input Validation**: All inputs validated with Pydantic
- **SQL Injection**: Protected with SQLAlchemy ORM

## ğŸ“ˆ Performance Optimization

- **Async Operations**: Full async/await implementation
- **Connection Pooling**: Database connection optimization
- **Caching**: Implement Redis for frequently accessed data
- **CDN**: Use CDN for static assets in production
- **Compression**: Enable gzip compression

## ğŸ› Troubleshooting

### **Common Issues**

1. **Database Connection Errors**
   ```bash
   # Reinitialize database
   python -c "from backend.db import init_db; import asyncio; asyncio.run(init_db())"
   ```

2. **API Import Errors**
   ```bash
   # Install missing dependencies
   pip install gnews transformers torch
   ```

3. **Frontend Build Issues**
   ```bash
   # Clear cache and reinstall
   cd frontend
   rm -rf node_modules package-lock.json
   npm install
   ```

4. **CORS Issues**
   - Check `ALLOWED_ORIGINS` in `.env`
   - Verify frontend URL matches backend configuration

### **Logs and Debugging**
- Backend logs: Check terminal output
- Frontend logs: Browser developer console
- Database logs: SQLAlchemy echo mode

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Reddit API for data access
- Google Gemini for AI capabilities
- Hugging Face for pre-trained models
- FastAPI and React communities

## ğŸ“ Support

For support and questions:
- Create an issue in the repository
- Check the troubleshooting section
- Review API documentation at `/docs`

---

**Built with â¤ï¸ for intelligent news analysis**
